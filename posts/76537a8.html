<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Flink Hive Connector读写源码解析 - Codedm的Java小站</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Codedm的Java小站"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Codedm的Java小站"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="本篇文章对应的Issues，Issues代表我文章创作的过程。(点击我)Flink实现Hive中表数据的读写操作首先要获取到每张表的元数据，通过表的元数据信息才能获取到数据文件的存储路径、存储格式、是否分区、分区规则。这样才能从HDFS对应的路径中获取到对应的数据，并使用对应的存储格式来解析文件。Flink Hive的读写同样使用Connector通用架构新Source（FLIP-27）和Sink"><meta property="og:type" content="blog"><meta property="og:title" content="Flink Hive Connector读写源码解析"><meta property="og:url" content="https://codedm.com/posts/76537a8.html"><meta property="og:site_name" content="Codedm的Java小站"><meta property="og:description" content="本篇文章对应的Issues，Issues代表我文章创作的过程。(点击我)Flink实现Hive中表数据的读写操作首先要获取到每张表的元数据，通过表的元数据信息才能获取到数据文件的存储路径、存储格式、是否分区、分区规则。这样才能从HDFS对应的路径中获取到对应的数据，并使用对应的存储格式来解析文件。Flink Hive的读写同样使用Connector通用架构新Source（FLIP-27）和Sink"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220920/43be348a6c5d477eb991ae1f20019991.png?x-oss-process=style/codedm"><meta property="og:image" content="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220914/33c0117958164715aa805ab0e114dba4.png?x-oss-process=style/codedm"><meta property="og:image" content="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220915/826d0c38d3ba49739cef6263cdac7a09.png?x-oss-process=style/codedm"><meta property="og:image" content="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220916/4cc600e281a7457fa02c85cf68a797ee.png?x-oss-process=style/codedm"><meta property="og:image" content="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220919/0c6cbc82f92a49f4a49738e68a336683.png?x-oss-process=style/codedm"><meta property="og:image" content="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220919/974ff4cb74214d30b6edf72e8afa8eda.png?x-oss-process=style/codedm"><meta property="article:published_time" content="2022-09-14T03:00:00.000Z"><meta property="article:modified_time" content="2022-10-15T13:12:36.907Z"><meta property="article:author" content="Codedm"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220920/43be348a6c5d477eb991ae1f20019991.png?x-oss-process=style/codedm"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://codedm.com/posts/76537a8.html"},"headline":"Flink Hive Connector读写源码解析","image":[],"datePublished":"2022-09-14T03:00:00.000Z","dateModified":"2022-10-15T13:12:36.907Z","author":{"@type":"Person","name":"Codedm"},"publisher":{"@type":"Organization","name":"Codedm的Java小站","logo":{"@type":"ImageObject","url":{"text":"Codedm"}}},"description":"本篇文章对应的Issues，Issues代表我文章创作的过程。(点击我)Flink实现Hive中表数据的读写操作首先要获取到每张表的元数据，通过表的元数据信息才能获取到数据文件的存储路径、存储格式、是否分区、分区规则。这样才能从HDFS对应的路径中获取到对应的数据，并使用对应的存储格式来解析文件。Flink Hive的读写同样使用Connector通用架构新Source（FLIP-27）和Sink"}</script><link rel="canonical" href="https://codedm.com/posts/76537a8.html"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.15.2/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?84bce1bdcb08243a9d3dcf57d6377a19";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-KT5435PTC2" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-KT5435PTC2');</script><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Codedm</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/categories/Java%E5%9F%BA%E7%A1%80/">Java基础</a><a class="navbar-item" href="/categories/Java%E8%BF%9B%E9%98%B6/">Java进阶</a><a class="navbar-item" href="/categories/JavaWeb/">JavaWeb</a><a class="navbar-item" href="/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/">微服务</a><a class="navbar-item" href="/categories/Flink/">Flink</a><a class="navbar-item" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="navbar-item" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-09-14T03:00:00.000Z" title="9/14/2022, 11:00:00 AM">2022-09-14</time>发表</span><span class="level-item"><time dateTime="2022-10-15T13:12:36.907Z" title="10/15/2022, 9:12:36 PM">2022-10-15</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Flink/">Flink</a></span><span class="level-item">14 分钟读完 (大约2110个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">Flink Hive Connector读写源码解析</h1><div class="content"><p><a target="_blank" rel="noopener" href="https://github.com/Code-dm/Re-learning-Java/issues/11">本篇文章对应的Issues，Issues代表我文章创作的过程。(点击我)</a><br>Flink实现Hive中表数据的读写操作首先要获取到每张表的元数据，通过表的元数据信息才能获取到数据文件的存储路径、存储格式、是否分区、分区规则。这样才能从HDFS对应的路径中获取到对应的数据，并使用对应的存储格式来解析文件。<br>Flink Hive的读写同样使用Connector通用架构新Source（<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface">FLIP-27</a>）和Sink。</p>
<span id="more"></span>
<h1 id="Flink-读取-Hive-配置信息"><a href="#Flink-读取-Hive-配置信息" class="headerlink" title="Flink 读取 Hive 配置信息"></a>Flink 读取 Hive 配置信息</h1><p>Flink 支持以批和流两种模式从 Hive 表中读取数据。批读的时候，Flink 会基于执行查询时表的状态进行查询。流读时将持续监控表，并在表中新数据可用时进行增量获取，默认情况下，Flink 将以批模式读取数据。<br>流读支持消费分区表和非分区表。对于分区表，Flink 会监控新分区的生成，并且在数据可用的情况下增量获取数据。对于非分区表，Flink 将监控文件夹中新文件的生成，并增量地读取新文件。</p>
<table>
<thead>
<tr>
<th>键</th>
<th>默认值</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>streaming-source.enable</td>
<td>false</td>
<td>Boolean</td>
<td>是否启动流读。注意：请确保每个分区&#x2F;文件都应该原子地写入，否则读取不到完整的数据。</td>
</tr>
<tr>
<td>streaming-source.partition.include</td>
<td>all</td>
<td>String</td>
<td>选择读取的分区，可选项为 <code>all</code> 和 <code>latest</code>，<code>all</code> 读取所有分区；<code>latest</code> 读取按照 ‘streaming-source.partition.order’ 排序后的最新分区，<code>latest</code> 仅在流模式的 Hive 源表作为时态表时有效。默认的选项是 <code>all</code>。在开启 ‘streaming-source.enable’ 并设置 ‘streaming-source.partition.include’ 为 ‘latest’ 时，Flink 支持 temporal join 最新的 Hive 分区，同时，用户可以通过配置分区相关的选项来配置分区比较顺序和数据更新时间间隔。</td>
</tr>
<tr>
<td>streaming-source.monitor-interval</td>
<td>None</td>
<td>Duration</td>
<td>连续监控分区&#x2F;文件的时间间隔。 注意: 默认情况下，流式读 Hive 的间隔为 ‘1 min’，但流读 Hive 的 temporal join 的默认时间间隔是 ‘60 min’，这是因为当前流读 Hive 的 temporal join 实现上有一个框架限制，即每个 TM 都要访问 Hive metastore，这可能会对 metastore 产生压力，这个问题将在未来得到改善。</td>
</tr>
<tr>
<td>streaming-source.partition-order</td>
<td>partition-name</td>
<td>String</td>
<td>streaming source 分区排序，支持 create-time， partition-time 和 partition-name。 create-time 比较分区&#x2F;文件创建时间， 这不是 Hive metastore 中创建分区的时间，而是文件夹&#x2F;文件在文件系统的修改时间，如果分区文件夹以某种方式更新，比如添加在文件夹里新增了一个文件，它会影响到数据的使用。partition-time 从分区名称中抽取时间进行比较。partition-name 会比较分区名称的字典顺序。对于非分区的表，总是会比较 ‘create-time’。对于分区表默认值是 ‘partition-name’。该选项与已经弃用的 ‘streaming-source.consume-order’ 的选项相同</td>
</tr>
<tr>
<td>streaming-source.consume-start-offset</td>
<td>None</td>
<td>String</td>
<td>流模式起始消费偏移量。如何解析和比较偏移量取决于你指定的顺序。对于 create-time 和 partition-time，会比较时间戳 (yyyy-[m]m-[d]d [hh:mm:ss])。对于 partition-time，将使用分区时间提取器从分区名字中提取的时间。 对于 partition-name，是字符串类型的分区名称(比如 pt_year&#x3D;2020&#x2F;pt_mon&#x3D;10&#x2F;pt_day&#x3D;01)。</td>
</tr>
</tbody></table>
<h1 id="Flink-读取-Hive-原理"><a href="#Flink-读取-Hive-原理" class="headerlink" title="Flink 读取 Hive 原理"></a>Flink 读取 Hive 原理</h1><p><img src="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220920/43be348a6c5d477eb991ae1f20019991.png?x-oss-process=style/codedm" alt="流程图"></p>
<p><img src="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220914/33c0117958164715aa805ab0e114dba4.png?x-oss-process=style/codedm" alt="HiveSource类依赖图"><br><code>HiveSource&lt;T&gt;</code>继承了<code>AbstractFileSource&lt;T, HiveSourceSplit&gt;</code>类，<code>AbstractFileSource</code>又实现了核心的<code>Source</code>接口。<br>Hive表中是不存储数据的，所有数据存储在HDFS中，所以<code>HiveSource</code>继承了<code>AbstractFileSource</code>抽象类。<br>通过<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface">FLIP-27</a>我们可以了解到<code>Source</code>类的作用：</p>
<ul>
<li>一个工厂类</li>
<li>用来创建<code>SplitEnumerator</code>和<code>SourceReader</code></li>
<li>创建用来生成<code>CheckPoint</code>的序列化类，以及从状态中恢复<code>Enumerator</code></li>
</ul>
<h2 id="HiveSourceBuilder"><a href="#HiveSourceBuilder" class="headerlink" title="HiveSourceBuilder"></a>HiveSourceBuilder</h2><p><code>org.apache.flink.connectors.hive.HiveSourceBuilder</code>类主要是通过配置信息构建<code>HiveSource</code>类。<br><code>HiveSourceBuilder</code>类中核心的方法：<code>buildWithBulkFormat</code>。<br><img src="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220915/826d0c38d3ba49739cef6263cdac7a09.png?x-oss-process=style/codedm" alt="buildHiveSource"></p>
<h2 id="HiveSource"><a href="#HiveSource" class="headerlink" title="HiveSource"></a>HiveSource</h2><p><code>HiveSource</code>构造方法中的参数：</p>
<ul>
<li><code>Path[] inputPaths</code>:<br> 文件系统中的一个目录或者一个文件，<code>buildHiveSource</code>传过来的参数是：<code>new Path[1]</code></li>
<li><code>FileEnumerator.Provider fileEnumerator</code>:<br> 一个可以创建<code>HiveSourceFileEnumerator</code>的工厂类</li>
<li><code>FileSplitAssigner.Provider splitAssigner</code>:<br> 创建<code>FileSplitAssigner</code>工厂类</li>
<li><code>BulkFormat&lt;T, HiveSourceSplit&gt; readerFormat</code>:<br> 首先了解什么是<code>BulkFormat</code>：<code>BulkFormat</code>是一个接口，<code>BulkFormat</code> 一次读取并解析一批记录。<code>BulkFormat</code>的实现包括<code>ORC Format</code>、<code>Parquet Format</code>、<code>HiveInputFormat</code>等。<br> 外部的<code>BulkFormat</code>类主要充当<code>reader</code>的配置持有者和工厂角色(用来创建<code>reader</code>的工厂)。<code>BulkFormat.Reader</code>是在<code>BulkFormat#createReader(Configuration, FileSourceSplit)</code>方法中创建的，然后完成读取操作。如果在流的<code>checkpoint</code>执行期间基于<code>checkpoint</code>创建<code>Bulk reader</code>，那么<code>reader</code>是在<code>BulkFormat#restoreReader(Configuration, FileSourceSplit)</code>方法中重新创建的。</li>
<li><code>ContinuousEnumerationSettings continuousEnumerationSettings</code>:<br> 流式读取持续监控分区和文件的配置，包括监控的时间间隔。<br> 如果是批量读取<code>continuousEnumerationSettings</code>为空，如果是流式读取<code>continuousEnumerationSettings</code>会被<code>new</code>出来。</li>
<li><code>int threadNum</code>:<br> 用来限制最大创建监控Hive分区和文件的线程数，在<code>org.apache.flink.connectors.hive.MRSplitsGetter</code>类中<code>Executors.newFixedThreadPool(threadNum);</code>限制线程池的数量。<br> 从<code>table.exec.hive.load-partition-splits.thread-num</code>中获取的参数。</li>
<li><code>JobConf jobConf</code>:<br> 通过<code>HiveConf</code>转成的<code>JobConf</code></li>
<li><code>ObjectPath tablePath</code>:<br>table&#x2F;view&#x2F;function的名称</li>
<li><code>List&lt;String&gt; partitionKeys</code>:<br> 分区键</li>
<li><code>ContinuousPartitionFetcher&lt;Partition, ?&gt; fetcher</code>:<br> 是一个Hive分区获取器，可以根据<code>previousOffset</code>获取之后的分区。需要利用<code>HiveContinuousPartitionFetcherContext-getComparablePartitionValueList</code>获取所有可比较的分区列表。</li>
<li><code>HiveTableSource.HiveContinuousPartitionFetcherContext&lt;?&gt; fetcherContext</code>:<br> <img src="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220916/4cc600e281a7457fa02c85cf68a797ee.png?x-oss-process=style/codedm" alt="FetcherContext"><br> 从<code>Hive</code>的<code>Meta Store</code>中获取表的分区的上下文。<br><code>HiveSource</code>继承<code>AbstractFileSource</code>类，<code>AbstractFileSource-createReader</code>会创建一个核心类<code>FileSourceReader</code>，用来读取分布式文件系统中的文件。<br><code>HiveSource-createEnumerator</code>会创建核心类<code>ContinuousHiveSplitEnumerator</code>(流式读取)或调用父类<code>createEnumerator</code>方法创建<code>StaticFileSplitEnumerator</code>(批方式读取)类。</li>
</ul>
<h2 id="ContinuousHiveSplitEnumerator"><a href="#ContinuousHiveSplitEnumerator" class="headerlink" title="ContinuousHiveSplitEnumerator"></a>ContinuousHiveSplitEnumerator</h2><p><img src="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220919/0c6cbc82f92a49f4a49738e68a336683.png?x-oss-process=style/codedm" alt="ContinuousHiveSplitEnumerator"><br>分区的发现分为初始化阶段和后续持续监控阶段，<code>ContinuousHiveSplitEnumerator</code>的作用是定时发现分布式文件系统中的分区。<code>ContinuousHiveSplitEnumerator</code>实现了<code>SplitEnumerator</code>类，程序会定时调用该类的<code>start()</code>方法用来监控分区。<br><code>start()</code>方法中<code>enumeratorContext.callAsync(monitor, this::handleNewSplits, discoveryInterval, discoveryInterval)</code>方法的入参：</p>
<ul>
<li>monitor：回调类，会定期调用该类的<code>call()</code>方法</li>
<li>this::handleNewSplits：传入的是一个函数。用来处理<code>monitor</code>发现的新分区</li>
<li>discoveryInterval：初始化延迟时间</li>
<li>discoveryInterval：周期延迟时间</li>
</ul>
<h3 id="PartitionMonitor-call-方法"><a href="#PartitionMonitor-call-方法" class="headerlink" title="PartitionMonitor#call()方法"></a>PartitionMonitor#call()方法</h3><p><img src="https://codedm.oss-cn-hangzhou.aliyuncs.com/images/20220919/974ff4cb74214d30b6edf72e8afa8eda.png?x-oss-process=style/codedm" alt="PartitionMonitor"><br><code>call()</code>方法会获取表的所有分区，并过滤掉<code>currentReadOffset</code>位点之后的之前的旧分区。然后根据这些分区循环生成<code>HiveSourceSplit</code>，最终返回<code>NewSplitsAndState</code>。<br><code>NewSplitsAndState</code>中存储三个全局变量：</p>
<ul>
<li>T offset: 最新的offset</li>
<li>Collection&lt;List<String>&gt; seenPartitions: 已经处理过的分区offset</li>
<li>Collection<HiveSourceSplit> newSplits: 监控到的新分区，如果没有监控到则为空</li>
</ul>
<h2 id="StaticFileSplitEnumerator"><a href="#StaticFileSplitEnumerator" class="headerlink" title="StaticFileSplitEnumerator"></a>StaticFileSplitEnumerator</h2><p><code>FileSource</code>批处理<code>SplitEnumerator</code>的具体实现。获取文件系统目录中所有文件并分配给<code>Reader</code>。<code>HiveSource</code>的批处理使用该类做处理。</p>
<h2 id="FileSourceReader"><a href="#FileSourceReader" class="headerlink" title="FileSourceReader"></a>FileSourceReader</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public FileSourceReader(</span><br><span class="line">            SourceReaderContext readerContext,</span><br><span class="line">            BulkFormat&lt;T, SplitT&gt; readerFormat,</span><br><span class="line">            Configuration config) &#123;</span><br><span class="line">        super(</span><br><span class="line">                () -&gt; new FileSourceSplitReader&lt;&gt;(config, readerFormat),</span><br><span class="line">                new FileSourceRecordEmitter&lt;&gt;(),</span><br><span class="line">                config,</span><br><span class="line">                readerContext);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>核心作用在构造方法中向父类传入<code>() -&gt; new FileSourceSplitReader&lt;&gt;(config, readerFormat)</code>。真正调用读取逻辑的是<code>FileSourceSplitReader</code></p>
<h2 id="FileSourceSplitReader"><a href="#FileSourceSplitReader" class="headerlink" title="FileSourceSplitReader"></a>FileSourceSplitReader</h2><p><code>FileSourceSplitReader</code>类中<code>fetch</code>方法调用批量读取方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public RecordsWithSplitIds&lt;RecordAndPosition&lt;T&gt;&gt; fetch() throws IOException &#123;</span><br><span class="line">  checkSplitOrStartNext();</span><br><span class="line"></span><br><span class="line">  final BulkFormat.RecordIterator&lt;T&gt; nextBatch = currentReader.readBatch();</span><br><span class="line">  return nextBatch == null</span><br><span class="line">          ? finishSplit()</span><br><span class="line">          : FileRecords.forRecords(currentSplitId, nextBatch);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>BulkFormat</code>在<code>HiveSource</code>构造方法参数中有详细讲解过。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Flink Hive Connector读写源码解析</p><p><a href="https://codedm.com/posts/76537a8.html">https://codedm.com/posts/76537a8.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Codedm</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2022-09-14</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-10-15</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/codedm-alipay.png" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/codedm-wxpay.png" alt="微信"></span></a></div><h3 class="menu-label has-text-centered">微信扫码关注我</h3><div class="buttons is-centered"><img src="/img/codedm-wx.jpg"></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/805c09f3.html"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Flink如何适配Hive中不同的数据存储格式</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/31388dbe.html"><span class="level-item">Flink Hive Connector创建Catalog的原理</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content twikoo" id="twikoo"></div><script src="https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js"></script><script>twikoo.init({
      envId: 'twikoo-3g6agapja2930969'
    });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/codedm-logo.png" alt="Codedm"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Codedm</p><p class="is-size-6 is-block">Codedm的Java小站</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国 * 南京</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">21</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Code-dm" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Code-dm"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Zhihu" href="https://www.zhihu.com/people/zhi-zhe-hu-zhi-zhe"><i class="fab fa-zhihu"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Flink-读取-Hive-配置信息"><span class="level-left"><span class="level-item">1</span><span class="level-item">Flink 读取 Hive 配置信息</span></span></a></li><li><a class="level is-mobile" href="#Flink-读取-Hive-原理"><span class="level-left"><span class="level-item">2</span><span class="level-item">Flink 读取 Hive 原理</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#HiveSourceBuilder"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">HiveSourceBuilder</span></span></a></li><li><a class="level is-mobile" href="#HiveSource"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">HiveSource</span></span></a></li><li><a class="level is-mobile" href="#ContinuousHiveSplitEnumerator"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">ContinuousHiveSplitEnumerator</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#PartitionMonitor-call-方法"><span class="level-left"><span class="level-item">2.3.1</span><span class="level-item">PartitionMonitor#call()方法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#StaticFileSplitEnumerator"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">StaticFileSplitEnumerator</span></span></a></li><li><a class="level is-mobile" href="#FileSourceReader"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">FileSourceReader</span></span></a></li><li><a class="level is-mobile" href="#FileSourceSplitReader"><span class="level-left"><span class="level-item">2.6</span><span class="level-item">FileSourceSplitReader</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Docker/"><span class="level-start"><span class="level-item">Docker</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Flink/"><span class="level-start"><span class="level-item">Flink</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Java%E5%9F%BA%E7%A1%80/"><span class="level-start"><span class="level-item">Java基础</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A1%AB%E5%86%99%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">填写分类</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><span class="level-start"><span class="level-item">大数据</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">领域驱动设计</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><nav class="panel"><p class="panel-heading" style="color: #7a7a7a">Flink文章列表</p><a class="panel-block" href="/posts/3ae81791.html"><span class="panel-icon"><i class="fas fa-book" aria-hidden="true"></i></span>Flink Formats 使用以及原理</a><a class="panel-block" href="/posts/a4786e67.html"><span class="panel-icon"><i class="fas fa-book" aria-hidden="true"></i></span>Flink Projection 使用以及原理</a><a class="panel-block" href="/posts/fed98383.html"><span class="panel-icon"><i class="fas fa-book" aria-hidden="true"></i></span>Flink CheckPoint 使用以及原理</a><a class="panel-block" href="/posts/e220ca62.html"><span class="panel-icon"><i class="fas fa-book" aria-hidden="true"></i></span>Flink Hive Connector 实战使用</a><a class="panel-block" href="/posts/f3b4a32a.html"><span class="panel-icon"><i class="fas fa-book" aria-hidden="true"></i></span>Flink Hive Connector 简介</a><a class="panel-block" href="/posts/31388dbe.html"><span class="panel-icon"><i class="fas fa-book" aria-hidden="true"></i></span>Flink Hive Connector创建Catalog的原理</a><a class="panel-block is-active" href="/posts/76537a8.html"><span class="panel-icon"><i class="fas fa-book" aria-hidden="true"></i></span><span style="color: #3273dc">Flink Hive Connector读写源码解析</span></a><a class="panel-block" href="/posts/805c09f3.html"><span class="panel-icon"><i class="fas fa-book" aria-hidden="true"></i></span>Flink如何适配Hive中不同的数据存储格式</a><a class="panel-block" href="/posts/573ecee0.html"><span class="panel-icon"><i class="fas fa-book" aria-hidden="true"></i></span>Flink Hive 合并小文件原理</a></nav></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Codedm</a><p class="is-size-7"><span>&copy; 2023 Codedm</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>